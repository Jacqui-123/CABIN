
##CABIN Benthic data  -- 

Data wrangling, tidying and analysis for all regions within the Canadian Aquatic Biomonitoring Network.

##Part 1: Is there a difference between the percent sorted of samples, by region? 

```{r}

library(png)
library(dplyr)
library(tidyverse)
library(reticulate)
library(zoo)
library(lubridate)
library(ggplot2)
library(sf)
library(mapview)
library(gridExtra)
library(data.table)
library(scales) 
library(AICcmodavg)
library(lme4)
#library(MASS)
```

A) Load in Benthic CABIN data in one dataframe, with a column of the Region

```{r}

library(data.table)
files <- list.files(path = "/Users/LevyJ/Desktop/CABIN", pattern = "^cabin_benthic.*?\\.csv", full.names = TRUE) 
df_benthic <- map_df(files, ~read_csv(., col_types = cols(.default = "c")), .id = "Region", encoding = 'Latin-1') 

```


Load in Study (meta) CABIN data in one dataframe, with a column of the Region.
This has the lat/long coordinates

```{r}
library(data.table)
files <- list.files(path = "/Users/LevyJ/Desktop/CABIN", pattern = "^cabin_study.*?\\.csv", full.names = TRUE) 
df_study <- map_df(files, ~read_csv(., col_types = cols(.default = "c")), .id = "Region", encoding = 'Latin-1') 

```


Load in the Habitat data, with a column for each Region. 

```{r}
library(data.table)
files <- list.files(path = "/Users/LevyJ/Desktop/CABIN", pattern = "^cabin_habitat.*?\\.csv", full.names = TRUE) 
df_habitat <- map_df(files, ~read_csv(., col_types = cols(.default = "c")), .id = "Region", encoding = 'Latin-1') 

```


B) Rename the columns to be easier to work with - just for the benthic data, I did this in excel for the study data due to the French characters misbehaving (they refused to convert to UTF-8)
```{r}
df_benthic <- df_benthic %>%
  rename("Site_Visit_ID" = 'SiteVisitID/IdentifiantdeVisite',
         "Site" = "Site/Site",
         "Year" = "Year/Année",
         "Sampling_Device" = "SamplingDevice/Dispositifd'échantillonnage",
         "Kick_Time" = "KickTime/Périodedelapassedufilettroubleau",
         "Mesh_size" = "MeshSize/Maillage",
         "Subsample" =	"SubSample/Sous-échantillon",
         "Julian_day" ="JulianDay/JourJulien",
         "Total_sample" ="TotalSample/Échantillontotal",
         "Status" = "Status/État",
         "Taxonomist" = "Taxonomist/Taxonomiste",
         "organization" = "Organization/Organisation",
         "address" = "Address/Adresser",
         "city" = "City/Ville",
         "province" = "Province/Province",
         "phylum" = "Phylum/Phylum",
         "class" = "Class/Classe",
         "Order" = "Order/Ordre",
         "Family" = "Family/Famille",
         "Genus" = "Genus/Genre",
         "Species" = "Species/Espèce",
         "Replicate" = "Replicate/Réplicat",
         "Count" = "Count/Décompte",
         "ITIS" ="ITIS_TSN",
         "Valid" = "Valid/Valide")

```

Rename to make the habitat data easier to work with. Unit, year, sample_number were renamed in excel

```{r}

df_habitat <- df_habitat %>%
  rename("Site_Visit_Id" = 'SiteVisitID/IdentifiantdeVisite',
         "Site" = "Site/Site",
         "Julian_day" = "JulianDay/JourJulian",
         "Status" ="status",
         "Type" = "Type/Type",
         "Value" = "Value/Valeur",
         "Computed" = "Computed/Calculé",
         "Notes" = "Note/Remarque" ) %>%
  dplyr::select(Region, Site_Visit_Id, Site, Protocol, Julian_day, Year, Sample_Number, Status, QAQC, Type, Variable, VariableDescription, Unit, Value, MDL, Computed, Notes )

```


D) Get set up to join the benthic and study data sets.

Add the region names to the benthic data using the region names file (I made this file in excel)
```{r}
Region_names <- read.csv("Region_names.csv", colClasses =c("character", "character", "character")) 

df_benthic <- full_join(df_benthic, Region_names, by = 'Region')


```

Mutate a new column "unique ID" with the site visit ID, site, and year separated by a "-". This is so we have a unique id for each site visit and year.

benthic data: 

```{r}

df_benthic_newsite <- df_benthic %>%
  tidyr::unite("Unique_Id", c("Site_Visit_ID", "Site", "Year" ), sep = "_", remove = FALSE )

```

Do the same for the study data. Mutate a new column "unique ID" with the site visit ID, site, and year separated by a "-"

```{r}

df_study_newsite <- df_study %>%
  tidyr::unite("Unique_Id", c("SiteVisitID", "Site", "Year"), sep =  "_", remove = FALSE) 

```

Same for the habitat data. Mutate a new column "unique ID" with the site visit ID, site, and year separated by a "-"

```{r}

df_habitat_newsite <-df_habitat %>%
tidyr::unite("Unique_Id", c("Site_Visit_Id", "Site", "Year" ), sep = "_", remove = FALSE )

```

Sanity check- make sure the lengths of each new id column are the same, otherwise we might be missing data
```{r}

length(unique(df_benthic_newsite$Unique_Id)) #12028
length(unique(df_study_newsite$Unique_Id)) #12464
length(unique(df_habitat_newsite$Unique_Id)) #11591

#they're not the same, 400 less sites for the benthic data
#1000 less sites for WA/hab data. Likely techs didn't always sample benthic/hab data at every site

```

Sanity checks continued, checking the number of unique IDs for each region for the study and benthic data 
```{r}
#when I check regions 1-10 by changing "LIKE" number, unique length is different for every region. Maybe this is because there are additional habitat data or WQ observations, and this is where the difference is? There are consistently more obs for study/meta data.

library(sqldf)

Region_benthic <- sqldf("select * from df_benthic_newsite where Region Like '1' ")
Region_study <- sqldf("Select * from df_study_newsite where Region Like '1' ")

length(unique(Region_benthic$Unique_Id))
length(unique(Region_study$Unique_Id))

#Keep going, because it's likely just just due to other data sources. Going forwards make sure there are the same unique_id's for the data as after the study-benthic join. (benthic data n=12028 )


```

Join the study data and benthic data by the newly created Unique_Id column
```{r}

df_both <- left_join(df_benthic_newsite, df_study_newsite,  by =  "Unique_Id") 

length(unique(df_both$Unique_Id)) # should be n=12028 

#df both has 12028, which is the same as df_benthic. Left join retained all of the benthic sites, and it looks like they all have lat/long on them.


```

Join the study and benthic data set to the habitat data using the Unique_Id column

```{r}

df_all <- left_join(df_both, df_habitat_newsite, by = "Unique_Id" )


```

 
E) Get ready to graph.

Make a new column to account for the sample numbers- there are multiple sample numbers for each Unique_Id, with varying test/ref/pot ref. If we don't do this, it means that there are overlapping data points in the test and ref/pot ref graphs. 

```{r}

df_both <- df_both %>%
  tidyr::unite("Unique_Id_Sample", c("Unique_Id", "Sample_Number"), sep =  "_", remove = FALSE) 

length(unique(df_both$Unique_Id_Sample)) #n = 13399

```

Sanity checkpoint- check NAs
```{r}

colSums(is.na(df_both)) #We still have 2863 NAs in Subsample and none in Status. 

```

More sanity checks- count number of test, potential test, and reference sites there are. These should add to 13399
```{r}
df_both = subset(df_both, select = -c(province, Province))

length(unique(df_both$Unique_Id_Sample)) #13399


num_ref_sites <- sqldf( " select Status, Unique_Id_Sample
                     from df_both Where Status Like '%Refere%' 
                      Group by Unique_Id_Sample")


#number of no test (ref or pot ref) sites are 5623

num_test_sites <- sqldf("select Status, Unique_Id_Sample
                         from df_both where Status LIKE 'Test'
                         Group by Unique_Id_Sample")


#this checks out
#number of test sites are 7510, number of ref/pot ref sites 5889. Adding them = 13399
```

What Region has the NA's for Subsample?
```{r}

Reg2 <- sqldf( " Select * from df_both where Region_Name LIKE 'St. Lawrence Drainage Area'  " )
colSums(is.na(Reg2)) #all the 2863 NAs are in Region 2. 
#consider removing Region 2 when graphing? Reg2 = St. Lawrence Drainage Area

```

Continue graphing prep! 

First graph: 

Percent sorted by region. Select only the reference or potential reference sites
```{r}
#change Status and Subsample NAs to "Unknown" because apparently filter automatically removes NAs.
df_no_test <- df_both %>%
 replace_na(list(Status = "Unknown", Subsample = "Unknown")) %>% 
  filter(Status == "Reference" | Status == "Potential Reference") %>% 
  filter( Sampling_Device == 'Kick Net') %>%
  filter(str_detect(Unique_Id_Sample, "_1$")) %>%
  dplyr::select(Unique_Id_Sample, Region_Name, Subsample, Sample_Number, Sampling_Device, Status, Latitude, Longitude) %>%
  distinct() %>%
  mutate_at(c('Subsample'), as.numeric) 


df_test <- df_both %>%
  replace_na(list(Status = "Unknown", Subsample = "Unknown")) %>% 
  filter(Status == "Test" ) %>%
  filter( Sampling_Device == 'Kick Net') %>%
  filter( Sampling_Device == 'Kick Net') %>%
  filter(str_detect(Unique_Id_Sample, "_1$")) %>%
  dplyr::select(Unique_Id_Sample, Region_Name, Subsample,Sample_Number, Sampling_Device,Status, Latitude, Longitude) %>%
  distinct() %>%
  mutate_at(c('Subsample'), as.numeric)


length(unique(df_no_test$Unique_Id_Sample)) #4271
length(unique(df_test$Unique_Id_Sample)) #4607
#these add to 8878


```


Ignore this - this was to be able to figure out the overlapping sites in test/reference sites. Turns out it was due to sampling numbers not being accounted for. It's fixed now 
```{r}
# can get a list of all sites and see if they are equal, and which ones aren't and then go back and look at those and what's happening.
#need a list of test+notestnames and see how this compares to bothnames. 

both_names <- unique(df_both$Unique_Id)


test_names <- unique(df_no_test$Unique_Id)
notest_names <- unique(df_test$Unique_Id)

#combine these two lists

list <- unique(test_names %in% notest_names)

#there are 50 stations in both test and notest, which is weird. Could they have the same region? maybe need to try to combine by regions?
intersect(notest_names, test_names )

#looks like it's due to sample number differences! 
#Some Unique_Ids have sample 1,2,3 with a combination of test/reference sites
#went back and added a new column of "Unique_Id_Sample" to account for this.

```

Graph of percent sorted, by region. There could be some difference between regions
```{r}
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#999999", "#E69F00", "#56B4E9")

ggplot(df_no_test, aes(x = Region_Name, y = Subsample, fill = Region_Name )) +
geom_boxplot() +
  theme_bw() +
    theme(plot.title =  element_text(size = 10, hjust = .5, face = "bold")) +
       #  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
   stat_boxplot(geom = "errorbar", width = 0.25) +
  ggtitle( "Percent Sorted by Region \n(Potential Reference or Reference Sites) ") +
  theme(legend.position = 'none') +
    #theme(legend.background = element_rect(colour = 'black', fill = 'white', linetype='solid')) +
scale_x_discrete(labels = wrap_format(10)) +
  ylab("Percent Sorted") +
    scale_fill_manual(values=cbPalette) 
  



```


What is our n? How many data points are there for each region for ref/pot ref sites? 
```{r}

 dplyr::count(df_no_test, Region_Name, sort = TRUE) %>%
  mutate(sum(n))

```

Graph of percent sorted, by region, of only test sites.Looks like there are outliers

```{r}
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7", "#999999", "#E69F00", "#56B4E9")

df_test %>% 
  filter(Subsample <= 100) %>%
  ggplot( aes(x = Region_Name, y = Subsample, fill = Region_Name )) +
geom_boxplot() +
  theme_bw() +
    theme(plot.title =  element_text(size = 10, hjust = .5, face = "bold")) +
       #  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
   stat_boxplot(geom = "errorbar", width = 0.25) +
  ggtitle( "Percent Sorted by Region \n(Test Sites) ") +
  theme(legend.position = 'none') +
    #theme(legend.background = element_rect(colour = 'black', fill = 'white', linetype='solid')) +
scale_x_discrete(labels = wrap_format(10)) +
  ylab("Percent Sorted") +
    scale_fill_manual(values=cbPalette)

#looks like there are a few outliers- graph without these
```


What is our n? How many sites are there for the test data?
```{r}

 dplyr::count(df_test, Region_Name, sort = TRUE) %>%
  mutate(sum(n))

```


```



```{r}

```


```{r}




```


```{r}

```

```{r}



```



```{r}
```


```{r}
```

